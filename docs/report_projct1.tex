\documentclass[12pt,a4paper]{article}

% ------------------------------------------------------------
% PACKAGES
% ------------------------------------------------------------
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{physics}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{bm}
\usepackage{float}

\geometry{
  left=25mm,
  right=25mm,
  top=25mm,
  bottom=25mm
}

\onehalfspacing

% ------------------------------------------------------------
% TITLE
% ------------------------------------------------------------
\title{
    \textbf{Physics-Informed Neural Network (PINN) Solution of\\
    1D Steady-State Heat Conduction in a homogeneous rod}
}
\author{
Arya Abdollahi \\
Department of Mechanical Engineering \\
Iran University of Science and Technology \\
\texttt{arya.abdollahi.t@gmail.com}
}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This report presents a Physics-Informed Neural Network (PINNs) approach for solving the one-dimensional steady-state heat conduction equation in a homogeneous rod. The classical model is governed by a second-order ordinary differential equation with Dirichlet boundary conditions. The PINNs method embeds the governing physics directly into the loss function using automatic differentiation and requires no mesh or labeled data. Results show excellent agreement between the PINN solution and the analytical solution, with errors on the order of $10^{-4}$ after refinement using the L-BFGS optimizer.
\end{abstract}

\newpage

\tableofcontents

\newpage

% ------------------------------------------------------------
\section{Introduction}
Physics-Informed Neural Networks (PINNs) represent a category of deep learning techniques that integrate fundamental physical principles, represented by differential equations, within their training. Unlike conventional data-driven models, PINNs do not necessitate labeled data solutions; they instead utilize automatic differentiation to impose residuals from differential equations, boundary conditions, and additional constraints.

In this project, a PINN is developed to solve the classical one-dimensional steady-state heat conduction equation.
\begin{equation}
    \frac{d^2 T}{dx^2} = 0.
\end{equation}

The goal of this report is to:
\begin{itemize}
    \item Present the mathematical formulation of the problem.
    \item Derive the nondimensionalized form used for training.
    \item Construct the PINN architecture and loss function.
    \item Demonstrate numerical results and compare with the analytical solution.
\end{itemize}

This is the first project in a larger series exploring PINNs for fluid mechanics and heat transfer.

% ------------------------------------------------------------
\section{Mathematical Formulation}

\subsection{Physical Problem}
Consider a homogeneous rod of length $L$ with no internal heat generation. The governing equation for steady-state heat conduction is:
\begin{equation}
    \frac{d}{dx}\left( k \frac{dT}{dx} \right) = 0,
\end{equation}
where $k$ is the thermal conductivity (assumed constant).

This simplifies to:
\begin{equation}
    \frac{d^2 T}{dx^2} = 0.
\end{equation}

Boundary conditions are:
\begin{align}
    T(0) &= T_0, \\
    T(L) &= T_L.
\end{align}

\subsection{Nondimensionalization}
Define:
\[
\xi = \frac{x}{L}, \qquad \theta = \frac{T - T_0}{T_L - T_0}.
\]

The governing equation becomes:
\begin{equation}
    \frac{d^2 \theta}{d\xi^2} = 0,
\end{equation}
with boundary conditions:
\[
\theta(0) = 0, \qquad \theta(1) = 1.
\]

\subsection{Analytical Solution}
Integrating the nondimensional equation twice:
\[
\theta(\xi) = \xi.
\]

Dimensional temperature is recovered via:
\[
T(x) = T_0 + (T_L - T_0)\theta(\xi).
\]

% ------------------------------------------------------------
\section{Physics-Informed Neural Network}

\subsection{Neural Network Approximation}
We approximate the solution using a neural network:
\[
\theta_{\text{NN}}(\xi; \bm{p}),
\]
where $\bm{p}$ are network parameters (weights and biases).

A fully connected multilayer perceptron (MLP) is used, with $\tanh$ activation:
\[
\text{MLP}: \quad 1 \rightarrow 20 \rightarrow 20 \rightarrow 20 \rightarrow 1.
\]

\subsection{PDE Residual}
Using automatic differentiation:
\[
r_{\text{PDE}}(\xi) = \frac{d^2 \theta_{\text{NN}}}{d\xi^2}.
\]

The PDE loss is:
\[
\mathcal{L}_{\text{PDE}} = \frac{1}{N_f} \sum_{i=1}^{N_f} r_{\text{PDE}}(\xi_f^{(i)})^2,
\]
where $\xi_f^{(i)}$ are interior collocation points sampled in $(0,1)$.

\subsection{Boundary Condition Loss}
\[
\mathcal{L}_{\text{BC}} = \frac{1}{2}\left[ 
    (\theta_{\text{NN}}(0) - 0)^2 +
    (\theta_{\text{NN}}(1) - 1)^2
\right].
\]

\subsection{Total Loss}
The final loss is a weighted sum:
\[
\mathcal{L} = \mathcal{L}_{\text{PDE}} + \mathcal{L}_{\text{BC}}.
\]

\subsection{Training Procedure}
Two optimizers are used:
\begin{enumerate}
    \item Adam (first 5000 iterations)
    \item L-BFGS (refinement)
\end{enumerate}

Interior collocation points are sampled uniformly:
\[
\xi_f^{(i)} \sim \mathcal{U}(0,1).
\]

% ------------------------------------------------------------
\section{Results}

\subsection{PINN vs Analytical Solution}
Figure~\ref{fig:theta} compares the PINN prediction with the analytical solution.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/results_theta.png}
    \caption{PINN prediction vs analytical solution.}
    \label{fig:theta}
\end{figure}

\subsection{Absolute Error}
The error is defined as:
\[
e(\xi) = \left| \theta_{\text{NN}}(\xi) - \xi \right|.
\]

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/results_error.png}
    \caption{Absolute error distribution along the rod.}
\end{figure}

\subsection{Loss History}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/loss_history.png}
    \caption{Training loss history.}
\end{figure}

\subsection{Error Metrics}
Relative $L^2$ error:
\[
\frac{
\left\| \theta_{\text{NN}} - \theta_{\text{exact}} \right\|_2
}{
\left\| \theta_{\text{exact}} \right\|_2
}
\approx 10^{-4}.
\]

Maximum absolute error:
\[
\max_{\xi\in[0,1]} e(\xi) \approx 10^{-4}.
\]

% ------------------------------------------------------------
\section{Conclusion}

This project demonstrates that a Physics-Informed Neural Network can accurately solve the 1D steady-state heat conduction equation using only the governing physics and boundary conditions, without requiring any labeled data. The PINN solution exhibits excellent agreement with the analytical solution, with very low error after refinement using the L-BFGS optimizer.

This forms a foundation for more advanced extensions including:
\begin{itemize}
    \item heat conduction with internal heat generation,
    \item nonlinear conduction ($k = k(T)$),
    \item multidimensional PDEs,
    \item inverse problems.
\end{itemize}

% ------------------------------------------------------------
\bibliographystyle{unsrt}
\begin{thebibliography}{9}

\bibitem{raissi2019pinn}
M.~Raissi, P.~Perdikaris, and G.~E. Karniadakis.
\newblock Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.
\newblock \emph{Journal of Computational Physics}, 378:686--707, 2019.

\bibitem{karniadakis2021pinn}
G.~E. Karniadakis, I.~G. Kevrekidis, L.~Lu, et al.
\newblock Physics-informed machine learning.
\newblock \emph{Nature Reviews Physics}, 3(6):422--440, 2021.

\end{thebibliography}

\end{document}
